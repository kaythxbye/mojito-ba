\documentclass[a4paper,
		12pt,
		parskip=full,
		titlepage
		]{scrartcl}

\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{hyperref}
\usepackage{float}
\usepackage{scrpage2} %use this instead of headings due to bug in KOMA-script
\usepackage[draft=false,babel,tracking=true,kerning=true,spacing=true]{microtype}

\usepackage{paralist}
\usepackage[section]{placeins} %don't float to next section

\usepackage[lofdepth,lotdepth]{subfig}

%\usepackage{minted}

%\hyphenpenalty=10000
% Hurenkinder und Schusterjungen verhindern
\clubpenalty=10000
\widowpenalty=10000
\displaywidowpenalty=10000

%\geometry{a4paper,left=40mm,right=40mm, top=20mm, bottom=40mm}

\linespread{1.25}

\graphicspath{{abbildungen/}} 
\titleformat{\section}[block]{\sffamily\Large\bfseries\filcenter}{\thesection}{1em}{}
\pagestyle{empty}

\newcommand{\blankpage}{
\newpage
\thispagestyle{empty}
\mbox{}
\newpage
}

%opening
\title{Measurements and Optimizations with Just-In-Time Code Generation on the Openflow Reference Implementation}
\author{Samuel Brack}
\date{\today}

\begin{document}
\thispagestyle{empty}

\hspace{20cm}
\vspace{-3cm}

\begin{figure}[H] \hspace{11cm}
\includegraphics[width=3.2 cm]{HU_Logo}
\end{figure}
% \vspace{5cm}
\begin{center}
  % \vspace{0.5 cm}
  \huge{\bf Measurements and Optimizations with Just-In-Time Code Generation on the Openflow Reference Implementation} \\ % Hier fuegen Sie den Titel Ihrer Arbeit ein.
  \vspace{1cm}
  \LARGE  Bachelorarbeit \\ % Geben Sie anstelle der Punkte an, ob es sich um eine
                % Diplomarbeit, eine Masterarbeit oder eine Bachelorarbeit handelt.
  \vspace{1cm}
  \Large zur Erlangung des akademischen Grades \\
  Bachelor of Science (B. Sc.)\\ % Bitte tragen Sie hier anstelle der Punkte ein:
         % Diplominformatiker(in),
         % Bachelor of Arts (B. A.),
         % Bachelor of Science (B. Sc.),
         % Master of Education (M. Ed.) oder
         % Master of Science (M. Sc.).
  \vspace{1.5cm}
  {\large
    \bf{
      \scshape
      Humboldt-Universit\"at zu Berlin \\
      Mathematisch-Naturwissenschaftliche Fakult\"at II \\
      Institut f\"ur Informatik\\
    }
  } 
  % \normalfont
\enlargethispage{10\baselineskip}
\end{center}
\vspace {1 cm}% gegebenenfalls kleiner, falls der Titel der Arbeit sehr lang sein sollte (original: 4cm)
%{3.2 cm} bei Verwendung von scrreprt, gegebenenfalls kleiner, falls der Titel der Arbeit sehr lang sein sollte
{\large
  \begin{tabular}{llll}
    eingereicht von:    &Samuel Brack  && \\ % Bitte Vor- und Nachnamen anstelle der Punkte eintragen.
    geboren am:         &27. März 1992  && \\
    in:                 &Memmingen  && \\
    &&&\\
    Gutachter: &Prof. Dr. Björn Scheuermann  && \\
              &Prof. Dr. Jens-Peter Redlich  && \\% Bitte Namen der Gutachter(innen) anstelle der Punkte eintragen
                 % bei zwei männlichen Gutachtern kann das (innen) weggestrichen werden
    &&&\\
    eingereicht am:     &   \hspace{3cm} verteidigt am: &  \\ % Bitte lassen Sie
                                    % diese beiden Felder leer.
                                    % Loeschen Sie ggf. das letzte Feld, wenn
                                    % Sie Ihre Arbeit laut Pruefungsordnung nicht
                                    % verteidigen muessen.
  \end{tabular}
}

\newpage


\chapter{Statement of authorship}

\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Selbststaendigkeitserklaerung
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\parindent 0cm
%%%%%%%%%%%%%%%%%%%%%%%%%%english version%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
I declare that I completed this thesis on my own and that information which has been
directly or indirectly taken from other sources has been noted as such. Neither this
nor a similar work has been presented to an examination committee.

  \vspace{3\baselineskip}
 
  Berlin, \today \hspace{0.25\linewidth}\parbox{0.3\linewidth}{\dotfill}
}
\newpage

%\begin{abstract}

%\end{abstract}

\addcontentsline{toc}{section}{Contents}
\setcounter{page}{1}
\tableofcontents{}

\pagebreak

\pagestyle{scrheadings}

\section{Introduction}
\subsection{The Packet Classification Problem}
The growth of the Internet constantly poses new challenges to the producers of network equipment.
Today's applications like Multimedia, Web and Voice over IP are dependent on a transport network (the Internet) with
high data rates, low latency, soft realtime properties and quality of service mechanisms.
This catalogue of network parameters is already implemented in the Internet protocol stack.

However, due to Moore's Law the growth of the actual data traffic must be engineered in faster hardware on the nodes handling this traffic.

Additionally, the number of hosts is growing steadily.
This also contributes to a denser address space in case of IPv4.
Usually, this leads to an increasing size of rule sets in the respective Internet traffic handlers. %TODO: position 1 absatz weiter?

The critical points in the internet's architecture concerning performance are the stations which have to decide for each packet what to do.
These are mostly firewalls, Level-2-Switches and Level-3-Routers.
In general, these machines inspect the header data of every incoming IP packet and process it following a rule set that has been specified before.
These rule sets can be mostly static (e.g. in case of a small SOHO router) or very dynamic (e.g. in a large stateful firewall).

One main point in optimization therefore lies in the matching algorithms executing this process.
Many traditional rule sets require five header fields for matching: Source IP address, destination IP address, transport protocol, source port and destination port.
The last two fields imply the usage of TCP or UDP as transport protocol, as other protocols may not know the concept of ports (e.g. ICMP). %TODO: quote RFCs
But there can be other relevant header fields, too, for example VLAN tags, QoS information or MAC source and destination addresses.

Matching algorithms become slower the more header fields they have to match.
Additionally, some fields require rules that imply certain ranges or prefixes, for example IP addresses.
A detailed description of the special role of prefixes is described in section \glqq Longest Prefix Matching\grqq.
These constraints make it more difficult to implement simple matching algorithms and in order to match with high speed, more sophisticated
algorithms have to be used for these fields.

\subsection{Longest Prefix Matching}
A common example for non-trivial matchable fields are IP forwarding tables, where rules are normally defined as IP prefixes.
Prefixes in IP addresses correspond to subnets, because in IP prefixes there is always a certain amount of fixed bits at the beginning of the address
and the bits after that are free to choose.

TODO: Example (with graphics)

Therefore, an algorithm used for matching packets has to be capable of longest prefix matching.

%An example for a prefix of an IPv4 address can look as follows:
%0110 1011 0001...
%This means that the first 12 bit of the address space are fixed and that the remaining 20 bits may be choosen freely.
%Now, that rule has to match packets with addresses from 0110 1011 0001 0000 0000 0000 0000 0000 up to
%0110 1011 0001 1111 1111 1111 1111 1111. %TODO: unschön? evtl umformulieren

%TODO: Openflow/SDN
\subsection{OpenFlow}
Software Defined Networking (SDN) describes the general idea to decouple the two tasks of network hardware and to introduce a new layer of abstraction in networking. %quote: sdn-whitepaper
These networks are separated into two logical units: the control and the data plane.
The control plane is used for configuring and updating the network hardware, e.g. inserting new rules into a firewall.
The data plane handles the incoming traffic and acts accordingly to the objectives defined in the control plane.

One popular instance of an SDN is OpenFlow.
This project is intended to establish a virtual network system on real hardware for educational and research use cases.
A key feature of OpenFlow is the control channel system.
One controller has connections to all existing hard- and software switches and can define their behaviour from a central position.
The controlled SDN switch then acts accordingly and handles the traffic as required.

Another key feature of SDN marks the ability to change the underlying hardware transparently.
The abstraction layer hides the details of the different systems so that the configuration on controller level can remain regardless of the hardware used.

The main objective of this work is to implement a faster matching engine in the software switch of the OpenFlow 1.0 reference implementation.
Currently, that matching engine uses a linear search in the specified rule set when classifying packets.
This approach may be fast enough in cases of small rule sets but with a growing number of rule in its database, the efficiency of a linear search decreases.


\section{Related Work}
Speeding up packet classification is one of the current research topics in the computer network community.
Therefore, several algorithms have been developed in the last years.
The bitvector algorithm is not the only promising idea to speed up packet matching in modern network hardware.
An overview over these algorithms can be gained from \cite{algorithms_survey}.%TODO
Approaches to this problem include the usage of tries, hash maps or geometric algorithms\cite{hicuts}
in order to perform significantly faster than searching in a linear list.

Real-world applications of these theoretical concepts are numerous and have been evaluated in different projects.
Following, there is an overview over different projects using a software packet filter environment.

The Iptables\cite{iptables} packet filter was improved in the HiPAC project \cite{hipac}, which was founded in a diploma thesis \cite{heinzhigh}.
Another project focuses on the implementation of EffiCuts in an OpenFlow environment \cite{stimpfling2013optimal}.
They also faced the challenge to improve the efficiency of packet classification on more than the usual five-tuple of header fields.
OpenFlow 1.0.0 \cite{openflow_spec10} requires at least 12 header fields to be matched, later versions are operating on even larger sets.
To address this problem, they extended the original EffiCuts algorithm in order to achieve a lower memory usage profile.

Other research groups focus on implementing wire speed packet matching in (programmable) hardware instead of software.
The bitvector approach \cite{bv} has been evaluated in FPGAs \cite{bitvector_fpga} \cite{qu2013fast}.
However, these papers mainly focus on five-tuple rule sets, which decreases the complexity of the problem compared to an OpenFlow 12-tuple.

Further improvement on the bitvector algorithm includes the elimination of the linear processing of the resulting bitvectors itself:
When all dimensions are matched and the resulting bitvectors are retrieved, these vectors have to be ANDed bit per bit until a one bit is found.
This obviously results in an $\mathcal O(n)$ worst case runtime.
The ABV algorithm \cite{abv} implements a hierarchical system of bitvectors with fixed length and runs in $\mathcal O(log\ n)$.
However, more memory space is needed to store the bitvectors of the respective hierarchies.

Another approach to improve matching performance in a packet filter is to reorganize the rule set.

One way to perform such a reorganization is the compression of the rule set as introduced in \cite{firewall_compressor} and \cite{redundancy_removal}.
They reduce the number of the rules significantly whilst persisting its semantics.
These optimizations can be done offline and before the rule set is loaded into the firewall.
Additionally, the firewall can perform a heuristic analysis of the traffic patterns and re-order the rule set accordingly while operating.

The advantage of that strategy is that the matching engine itself has not to be changed and can be left untouched.
This can be useful in black box scenarios, where the matching engine's source code is not open to the end user.
However, that idea requires to reorganize the desired rule set and makes updating more complex.
In case of high-frequent updates this strategy will hit its limitations, as the optimization steps often require the consideration of the entire rule set and not only the updated part.

\section{The Bitvector Algorithm}
\subsection{General Description}
The bitvector algorithm \cite{bv} is an efficient solution to the packet classification problem, which explained in the introduction section.
This algorithm is designed for matching multi-dimensional header data in a short time.
The basic idea of this algorithm is to think of the ruleset as a set of multi-dimensional hypercubes.
Each header field represents one dimension in this geometric object, so that every hypercube (which represents exactly one rule) has as many dimensions as the packet matching engine is operating on.
The extent of one rule in one dimension is therefore an interval between two integers.
They are determined by projecting the hypercube onto the relevant dimension.
If cubes (and their respective rules) are overlapping, one point on the dimension can be the target of multiple cubes' projections. 
This property leads to a model, where for any given point in a matching dimension, there is a set of cubes (and therefore rules) that are projected on intervals containing this point.

If there are no matching rules for a point there is no cube projecting an interval to the relevant dimension.

The bitvector algorithm collects these projected rules for every dimension.
After that, the edges of the rules' intervals are determined.
Every edge then stores a vector of bits with $n$ bits length.
For each original rule $r$ in the rule set with $n$ rules this bit vector stores a $1$ if and only if $r$ is projected on the interval beginning at the current edge.
If $r$ is not projected on the current interval, a $0$ bit is stored.
This construction is done in every dimension for every edge.

\subsection{Lookup}
When looking up a packet with the bitvector algorithm, one has to determine a point to look up in every matching dimension.
These points are header data, for example one point is the source IP address, another one is the destination IP address or the VLAN ID.
When all relevant points are determined the lookup process works as follows:
Firstly, there is a search for the target point in every dimension.
In this implementation, binary search returns the nearest left edge (constructed when inserting the rules) of the search space.
This edge contains the bitvector with $n$ bits length, where $n$ is the size of the ruleset.

Secondly, all bitvectors from all dimensions are joined by a bitwise AND.
The resulting vector then indicates by a $1$ at position $p$ that the packet has matched rule $p$.
Generally, there can be one or more matching rules, for example when default rules exist, that match every packet.
In order to determine the highest priority matching rule, the resulting bitvector is then scanned for the leftmost set 1-bit.
The index of this bit in the bitvector then determines the best matching rule in the ruleset.
After that, the actions defined in the rule can be executed by the network device and the next packet in the queue can be matched.

\subsection{JIT lookup}
To further speed up the lookup process, another optimization has been implemented.
At each lookup, the algorithm has to perform a binary search on the bitvectors' locations in each dimension in order to find the matching bitvector for the current packet.
These locations can be interpreted as delimiters between the realms of the bitvectors.
In the above example, if the lookup process receives a packet with a source IP address value of 10.0.0.3, the algorithm has to find the first bitvector in the source IP dimension. %TODO: example abgleichen!
For every header field in the 12-dimensional OpenFlow header the algorithm has to yield exactly one bitvector.
This lookup process over the entire delimiter space requires several memory accesses for every lookup.
The general idea to speed up this operation is to precompute a function that is specific for each dimension and returns the bitvector's index in one dimension when given the header value to be matched.

The function is designed to have zero memory accesses when looking up header values.
Therefore it performs the binary search only on precomputed values, which leads to the necessity of rebuilding the function at every rule set update.
Clearly, that leads to a performance disadvantage for fast changing rule sets at the benefit of having generally faster lookups.

Implementing that functionality has lead to a just in time generated function written in machine language\footnote{The x86\_64 architecture with Intel assembly language has been used.}.

The algorithm used in this implementation is a slightly modified binary search.
%TODO: Pseudocode hier einfügen

Figure TODO shows the significant loss in efficiency when inserting rules. %TODO: Grafik
The two graphs show the duration of an update with different sized rule sets in the JIT implementation and in the conventional approach.
Because of the requirement that the matching engine has to be operable immediately after every update operation, every update implies a complete regeneration of the JIT code.
That behaviour explains the additional update time seen in the measured data. 

\section{Evaluation}
\subsection{Unit Tests}
An important goal in every software project is to ensure that the program operates correctly.
The first step in this quality assurance process is to design unit tests for the modules in the software.
In this project the matching engines have been tested separately before integrating them into the OpenFlow switch.
Additionally, the just in time generated code has been tested to work properly.
Erroneous behaviour in that part of the code is not easily debuggable.

\subsection{Acceptance Test}
In order to guarantee the correctness of the two new implementations a predefined acceptance test was developed.
A reasonable assumption is that, if given a rule set and a corresponding trace, the old and new implementations are behaving the same.
This was tested by deriving traces from randomly generated rule sets with the Classbench\cite{classbench_website} tool \textsf{trace\_generator}.

\subsection{Performance Evaluation}

\newpage
\addcontentsline{toc}{section}{References}
\bibliographystyle{acm}
\bibliography{references,paper-build/conferences-crossref}

\end{document}
