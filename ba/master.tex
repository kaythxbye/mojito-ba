\documentclass[a4paper,
		12pt,
		parskip=full,
		titlepage
		]{scrartcl}

\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{hyperref}
\usepackage{float}
\usepackage{csquotes}
\usepackage{scrpage2} %use this instead of headings due to bug in KOMA-script
\usepackage[draft=false,babel,tracking=true,kerning=true,spacing=true]{microtype}

\usepackage{paralist}
\usepackage[section]{placeins} %don't float to next section

\usepackage[lofdepth,lotdepth]{subfig}

%\usepackage{minted}

%\hyphenpenalty=10000
% Hurenkinder und Schusterjungen verhindern
\clubpenalty=10000
\widowpenalty=10000
\displaywidowpenalty=10000

%\geometry{a4paper,left=40mm,right=40mm, top=20mm, bottom=40mm}

\linespread{1.25}

\graphicspath{{abbildungen/}} 
\titleformat{\section}[block]{\sffamily\Large\bfseries\filcenter}{\thesection}{1em}{}
\pagestyle{empty}

\newcommand{\blankpage}{
\newpage
\thispagestyle{empty}
\mbox{}
\newpage
}

%opening
\title{Measurements and Optimizations with Just-In-Time Code Generation on the Openflow Reference Implementation}
\author{Samuel Brack}
\date{\today}

\begin{document}
\thispagestyle{empty}

\hspace{20cm}
\vspace{-3cm}

\begin{figure}[H] \hspace{11cm}
\includegraphics[width=3.2 cm]{HU_Logo}
\end{figure}
% \vspace{5cm}
\begin{center}
  % \vspace{0.5 cm}
  \huge{\bf Measurements and Optimizations with Just-In-Time Code Generation on the Openflow Reference Implementation} \\ % Hier fuegen Sie den Titel Ihrer Arbeit ein.
  \vspace{1cm}
  \LARGE  Bachelorarbeit \\ % Geben Sie anstelle der Punkte an, ob es sich um eine
                % Diplomarbeit, eine Masterarbeit oder eine Bachelorarbeit handelt.
  \vspace{1cm}
  \Large zur Erlangung des akademischen Grades \\
  Bachelor of Science (B. Sc.)\\ % Bitte tragen Sie hier anstelle der Punkte ein:
         % Diplominformatiker(in),
         % Bachelor of Arts (B. A.),
         % Bachelor of Science (B. Sc.),
         % Master of Education (M. Ed.) oder
         % Master of Science (M. Sc.).
  \vspace{1.5cm}
  {\large
    \bf{
      \scshape
      Humboldt-Universit\"at zu Berlin \\
      Mathematisch-Naturwissenschaftliche Fakult\"at II \\
      Institut f\"ur Informatik\\
    }
  } 
  % \normalfont
\enlargethispage{10\baselineskip}
\end{center}
\vspace {1 cm}% gegebenenfalls kleiner, falls der Titel der Arbeit sehr lang sein sollte (original: 4cm)
%{3.2 cm} bei Verwendung von scrreprt, gegebenenfalls kleiner, falls der Titel der Arbeit sehr lang sein sollte
{\large
  \begin{tabular}{llll}
    eingereicht von:    &Samuel Brack  && \\ % Bitte Vor- und Nachnamen anstelle der Punkte eintragen.
    geboren am:         &27. März 1992  && \\
    in:                 &Memmingen  && \\
    &&&\\
    Gutachter: &Prof. Dr. Björn Scheuermann  && \\
              &Prof. Dr. Jens-Peter Redlich  && \\% Bitte Namen der Gutachter(innen) anstelle der Punkte eintragen
                 % bei zwei männlichen Gutachtern kann das (innen) weggestrichen werden
    &&&\\
    eingereicht am:     &   \hspace{3cm} verteidigt am: &  \\ % Bitte lassen Sie
                                    % diese beiden Felder leer.
                                    % Loeschen Sie ggf. das letzte Feld, wenn
                                    % Sie Ihre Arbeit laut Pruefungsordnung nicht
                                    % verteidigen muessen.
  \end{tabular}
}

\newpage


\chapter{Statement of authorship}

\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Selbststaendigkeitserklaerung
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\parindent 0cm
%%%%%%%%%%%%%%%%%%%%%%%%%%english version%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
I declare that I completed this thesis on my own and that information which has been
directly or indirectly taken from other sources has been noted as such. Neither this
nor a similar work has been presented to an examination committee.

  \vspace{3\baselineskip}
 
  Berlin, \today \hspace{0.25\linewidth}\parbox{0.3\linewidth}{\dotfill}
}
\newpage

%\begin{abstract}

%\end{abstract}

\addcontentsline{toc}{section}{Contents}
\setcounter{page}{1}
\tableofcontents{}

\pagebreak

\pagestyle{scrheadings}

\section{Introduction}
\subsection{The Packet Classification Problem}
The growth of the Internet constantly poses new challenges to the producers of network equipment.
Today's applications like Multimedia, Web and Voice over IP are dependent on a transport network with
high data rates, low latency, soft realtime properties and quality of service mechanisms.
This catalogue of network parameters is already implemented in the Internet protocol stack.
However, the growth of the actual traffic itself leads to a steady demand for faster hardware handling the traffic on the networks. 

Additionally, the number of hosts is growing permanently.
This also contributes to a denser populated address space in case of IPv4.
Historically, the IPv4 address space was divided into three classes\cite{rfc1466}.
After 1993 the concept of Classless Inter Domain Routing (CIDR) was introduced.
Firstly, an overview over the classful Internet and its consequences on routing and the corresponding rule sets.

Very large networks were called Class A networks.
These networks were located in the address range of 0.0.0.0 to 127.255.255.255 and each network could include up to about 16 million hosts.
This means that only the first of the four bytes structuring an IPv4 address is fixed, the rest is freely choosable for each host by the owner of the address block.
Due to their size, the entire IPv4 address space can only contain 128 of these networks.
Class A networks were assigned to big companies and organisations in the early days of the Internet.

A more common class especially for smaller organisations like German universities were Class B networks.
These networks had two of the four bytes in an IPv4 address fixed.
This lead to 16384 possible Class B networks with up to about 65000 hosts each.
Similarly, Class C networks were alloted to small entities.
Each Class C network contains up to 254 hosts and has the first three of the four address bytes set.

This layout faciliated the routing problem.
Rule sets could be relatively organised and small.
For example, an entire Class An network only needed one routing rule to have its traffic routed there.
Additionally, the first byte of a network address already determined the affiliation in its net class.
On the other hand, this system had major disadvantages.
Firstly, there are only three sizes for networks.
This automatically leads to networks too big for the purpose and an enormous waste of addresses.
Another problem is the lack of flexibility.
Consider a network that has to be shrinked or enlargened.
That operation could only properly be executed by moving into another network class instead of extending the 
previously used address space into its \enquote{neighbouring} area.

In 1993, the IETF introduced Classless Inter Domain Routing\cite{rfc1518} \cite{rfc4632}.
The main idea is to give up the three static classes and to introduce dynamic subnet sizes.
In principle, an address can be part of a network of any size and is not bound to be in a certain class.
This flexibility leads to the necessity of defining the size of the subnet for every subnet.
In the old scheme, the address 1.2.3.4 was definitely in the Class A network 1.0.0.0 -- 1.255.255.255.
With CIDR, the containing address space must be determined by defining a fixed prefix for each of the addresses in the subnet.
Usually, this is done by adding a slash followed the number of fixed bits after the subnet's first address.
For example, the previous Class A network becomes 1.0.0.0/8, because the first 8 bit are fixed and the rest is part of the subnet.
With this notation, the entire Internet becomes 0.0.0.0/0 and one single host is for example 141.20.33.1/32.

\subsection{Longest Prefix Matching}
CIDR opens the opportunity to route different parts of a subnet to different places.
For example, a rule set can contain a rule for the address space 141.20.0.0/16 and another rule for the included subnet 141.20.33.0/24.
Packet matchers therefore need to have capabilities to match a packet to its longest matching prefix, as more special rules are normally higher prioritized.
Usually, CIDR leads to an increasing size of rule sets in the respective Internet traffic handlers. 
%TODO: Grafik zum Beispiel, mehr Text

\subsection{Affected Internet Infrastructure}
The critical points in the internet's architecture concerning performance are the stations which have to decide for each packet what to do.
These are mostly firewalls, Level-2-Switches and Level-3-Routers.
In general, these machines inspect the header data of every incoming IP packet and process it following a rule set that has been specified before.

One main point in optimization therefore lies in the matching algorithms executing this process. %TODO: überarbeiten ab hier
Many traditional rule sets require five header fields for matching: Source IP address, destination IP address, transport protocol, source port and destination port.
The last two fields imply the usage of TCP or UDP as transport protocol, as other protocols may not know the concept of ports (e.g. ICMP). %TODO: quote RFCs
But there can be other relevant header fields, too, for example VLAN tags, QoS information or MAC source and destination addresses.%bis hier

Matching algorithms become slower the more header fields they have to match.
Additionally, some fields require rules that imply certain ranges or prefixes, for example IP addresses.
These constraints make it more difficult to implement simple matching algorithms and in order to match with high speed, more sophisticated
algorithms have to be used for these fields.

A common example for non-trivial matchable fields are IP forwarding tables, where rules are normally defined as IP prefixes.


Therefore, an algorithm used for matching packets has to be capable of longest prefix matching.

%An example for a prefix of an IPv4 address can look as follows:
%0110 1011 0001...
%This means that the first 12 bit of the address space are fixed and that the remaining 20 bits may be choosen freely.
%Now, that rule has to match packets with addresses from 0110 1011 0001 0000 0000 0000 0000 0000 up to
%0110 1011 0001 1111 1111 1111 1111 1111. %TODO: unschön? evtl umformulieren

%TODO: Openflow/SDN
\subsection{OpenFlow}
Software Defined Networking (SDN) describes the general idea to decouple the two tasks of network hardware and to introduce a new layer of abstraction in networking. %quote: sdn-whitepaper
These networks are separated into two logical units: the control and the data plane.
The control plane is used for configuring and updating the network hardware, e.g. inserting new rules into a firewall.
The data plane handles the incoming traffic and acts accordingly to the objectives defined in the control plane.

One popular instance of an SDN is OpenFlow.
This project is intended to establish a virtual network system on real hardware for educational and research use cases.
A key feature of OpenFlow is the control channel system.
One controller has connections to all existing hard- and software switches and can define their behaviour from a central position.
The controlled SDN switch then acts accordingly and handles the traffic as required.

Another key feature of SDN marks the ability to change the underlying hardware transparently.
The abstraction layer hides the details of the different systems so that the configuration on controller level can remain regardless of the hardware used.

The main objective of this work is to implement a faster matching engine in the software switch of the OpenFlow 1.0 reference implementation.
Currently, that matching engine uses a linear search in the specified rule set when classifying packets.
This approach may be fast enough in cases of small rule sets but with a growing number of rule in its database, the efficiency of a linear search decreases.


\section{Related Work}
Speeding up packet classification is one of the current research topics in the computer network community.
Therefore, several algorithms have been developed in the last years.
The bitvector algorithm is not the only promising idea to speed up packet matching in modern network hardware.
An overview over these algorithms can be gained from \cite{algorithms_survey}.%TODO
Approaches to this problem include the usage of tries, hash maps or geometric algorithms\cite{hicuts}
in order to perform significantly faster than searching in a linear list.

Real-world applications of these theoretical concepts are numerous and have been evaluated in different projects.
Following, there is an overview over different projects using a software packet filter environment.

The Iptables\cite{iptables} packet filter was improved in the HiPAC project \cite{hipac}, which was founded in a diploma thesis \cite{heinzhigh}.
Another project focuses on the implementation of EffiCuts in an OpenFlow environment \cite{stimpfling2013optimal}.
They also faced the challenge to improve the efficiency of packet classification on more than the usual five-tuple of header fields.
OpenFlow 1.0.0 \cite{openflow_spec10} requires at least 12 header fields to be matched, later versions are operating on even larger sets.
To address this problem, they extended the original EffiCuts algorithm in order to achieve a lower memory usage profile.

Other research groups focus on implementing wire speed packet matching in (programmable) hardware instead of software.
The bitvector approach \cite{bv} has been evaluated in FPGAs \cite{bitvector_fpga} \cite{qu2013fast}.
However, these papers mainly focus on five-tuple rule sets, which decreases the complexity of the problem compared to an OpenFlow 12-tuple.

Further improvement on the bitvector algorithm includes the elimination of the linear processing of the resulting bitvectors itself:
When all dimensions are matched and the resulting bitvectors are retrieved, these vectors have to be ANDed bit per bit until a one bit is found.
This obviously results in an $\mathcal O(n)$ worst case runtime.
The ABV algorithm \cite{abv} implements a hierarchical system of bitvectors with fixed length and runs in $\mathcal O(log\ n)$.
However, more memory space is needed to store the bitvectors of the respective hierarchies.

Another approach to improve matching performance in a packet filter is to reorganize the rule set.

One way to perform such a reorganization is the compression of the rule set as introduced in \cite{firewall_compressor} and \cite{redundancy_removal}.
They reduce the number of the rules significantly whilst persisting its semantics.
These optimizations can be done offline and before the rule set is loaded into the firewall.
Additionally, the firewall can perform a heuristic analysis of the traffic patterns and re-order the rule set accordingly while operating.

The advantage of that strategy is that the matching engine itself has not to be changed and can be left untouched.
This can be useful in black box scenarios, where the matching engine's source code is not open to the end user.
However, that idea requires to reorganize the desired rule set and makes updating more complex.
In case of high-frequent updates this strategy will hit its limitations, as the optimization steps often require the consideration of the entire rule set and not only the updated part.

\section{The Bitvector Algorithm}
\subsection{General Description}
The bitvector algorithm \cite{bv} is an efficient solution to the packet classification problem, which explained in the introduction section.
This algorithm is designed for matching multi-dimensional header data in a short time.
The basic idea of this algorithm is to think of the ruleset as a set of multi-dimensional hypercubes.
Each header field represents one dimension in this geometric object, so that every hypercube (which represents exactly one rule) has as many dimensions as the packet matching engine is operating on.
The extent of one rule in one dimension is therefore an interval between two integers.
They are determined by projecting the hypercube onto the relevant dimension.
If cubes (and their respective rules) are overlapping, one point on the dimension can be the target of multiple cubes' projections. 
This property leads to a model, where for any given point in a matching dimension, there is a set of cubes (and therefore rules) that are projected on intervals containing this point.

If there are no matching rules for a point there is no cube projecting an interval to the relevant dimension.

The bitvector algorithm collects these projected rules for every dimension.
After that, the edges of the rules' intervals are determined.
Every edge then stores a vector of bits with $n$ bits length.
For each original rule $r$ in the rule set with $n$ rules this bit vector stores a $1$ if and only if $r$ is projected on the interval beginning at the current edge.
If $r$ is not projected on the current interval, a $0$ bit is stored.
This construction is done in every dimension for every edge.

\subsection{Lookup}
When looking up a packet with the bitvector algorithm, one has to determine a point to look up in every matching dimension.
These points are header data, for example one point is the source IP address, another one is the destination IP address or the VLAN ID.
When all relevant points are determined the lookup process works as follows:
Firstly, there is a search for the target point in every dimension.
In this implementation, binary search returns the nearest left edge (constructed when inserting the rules) of the search space.
This edge contains the bitvector with $n$ bits length, where $n$ is the size of the ruleset.

Secondly, all bitvectors from all dimensions are joined by a bitwise AND.
The resulting vector then indicates by a $1$ at position $p$ that the packet has matched rule $p$.
Generally, there can be one or more matching rules, for example when default rules exist, that match every packet.
In order to determine the highest priority matching rule, the resulting bitvector is then scanned for the leftmost set 1-bit.
The index of this bit in the bitvector then determines the best matching rule in the ruleset.
After that, the actions defined in the rule can be executed by the network device and the next packet in the queue can be matched.

\subsection{JIT lookup}
To further speed up the lookup process, another optimization has been implemented.
At each lookup, the algorithm has to perform a binary search on the bitvectors' locations in each dimension in order to find the matching bitvector for the current packet.
These locations can be interpreted as delimiters between the realms of the bitvectors.
In the above example, if the lookup process receives a packet with a source IP address value of 10.0.0.3, the algorithm has to find the first bitvector in the source IP dimension. %TODO: example abgleichen!
For every header field in the 12-dimensional OpenFlow header the algorithm has to yield exactly one bitvector.
This lookup process over the entire delimiter space requires several memory accesses for every lookup.
The general idea to speed up this operation is to precompute a function that is specific for each dimension and returns the bitvector's index in one dimension when given the header value to be matched.

The function is designed to have zero memory accesses when looking up header values.
Therefore it performs the binary search only on precomputed values, which leads to the necessity of rebuilding the function at every rule set update.
Clearly, that leads to a performance disadvantage for fast changing rule sets at the benefit of having generally faster lookups.

Implementing that functionality has lead to a just in time generated function written in machine language\footnote{The x86\_64 architecture with Intel assembly language has been used.}.

The algorithm used in this implementation is a slightly modified binary search.
%TODO: Pseudocode hier einfügen

Figure TODO shows the significant loss in efficiency when inserting rules. %TODO: Grafik
The two graphs show the duration of an update with different sized rule sets in the JIT implementation and in the conventional approach.
Because of the requirement that the matching engine has to be operable immediately after every update operation, every update implies a complete regeneration of the JIT code.
That behaviour explains the additional update time seen in the measured data. 

\section{Evaluation}
\subsection{Unit Tests}
An important goal in every software project is to ensure that the program operates correctly.
The first step in this quality assurance process is to design unit tests for the modules in the software.
In this project the matching engines have been tested separately before integrating them into the OpenFlow switch.
Additionally, the just in time generated code has been tested to work properly.
Erroneous behaviour in that part of the code is not easily debuggable.

\subsection{Acceptance Test}
In order to guarantee the correctness of the two new implementations a predefined acceptance test was developed.
A reasonable assumption is that, if given a rule set and a corresponding trace, the old and new implementations are behaving the same.
This was tested by deriving traces from randomly generated rule sets with the Classbench\cite{classbench_website} tool \textsf{trace\_generator}.

\subsection{Performance Evaluation}
The evaluation of the performance of the newly implemented matching algorithm has been executed in a virtualized environment.
\textsf{mininet}\cite{mininet} provides an easily usable and lightweight virtual network on a local computer.
It creates two new local interfaces and connects them through a local OpenFlow switch.
This switch can be configured with \textsf{dpctl}, a tool included in the toolchain of the OpenFlow reference implementation.
Rule set updates thus are done via a command line call of that tool.
The evaluation system is a Lenovo Thinkpad T61 laptop with an Intel Core2Duo dual core CPU and 3 GB of memory running a recent Arch Linux. %TODO: Prozessormodell

The matching performance evaluation was setup in the following way.
\begin{itemize}
    \item Creation of different sized rule sets from 50 to 1000 rules.
        For measuring average performances there are 15 rule sets created for every rule set size.
    \item Generating the best, average and worst case sub-rule sets. 
        Each original rule set is split into thirds and these are saved separately
    \item Generating traces for every sub-rule set.
        Using the Classbench\cite{classbench_website} tool, a packet trace is generated for every previously generated rule set.
        That means that for every rule set three traces are produced: one for the best case sub-rule set, one for the average and one for the worst case.
\end{itemize}
A packet trace consists of packet header data like IP source and destination addresses, transport and Internet protocols et cetera.
Every trace entry can be translated into a packet that is sent into the OpenFlow switch's matching engine.

\newpage
\addcontentsline{toc}{section}{References}
\bibliographystyle{acm}
\bibliography{references,paper-build/conferences-crossref,rfc}

\end{document}