\documentclass[a4paper,
		12pt,
		parskip=full,
		titlepage
		]{scrartcl}

\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{hyperref}
\usepackage{float}
\usepackage{csquotes}
\usepackage{scrpage2} %use this instead of headings due to bug in KOMA-script
\usepackage[draft=false,babel,tracking=true,kerning=true,spacing=true]{microtype}
\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{paralist}
\usepackage[section]{placeins} %don't float to next section

\usepackage[lofdepth,lotdepth]{subfig}

%\usepackage{minted}

%\hyphenpenalty=10000
% Hurenkinder und Schusterjungen verhindern
\clubpenalty=10000
\widowpenalty=10000
\displaywidowpenalty=10000

%\geometry{a4paper,left=40mm,right=40mm, top=20mm, bottom=40mm}

\linespread{1.25}

\graphicspath{{abbildungen/}} 
\titleformat{\section}[block]{\sffamily\Large\bfseries\filcenter}{\thesection}{1em}{}
\pagestyle{empty}

\newcommand{\blankpage}{
\newpage
\thispagestyle{empty}
\mbox{}
\newpage
}

%opening
\title{Measurements and Optimizations with Just-In-Time Code Generation on the Openflow Reference Implementation}
\author{Samuel Brack}
\date{\today}

\begin{document}
\thispagestyle{empty}

\hspace{20cm}
\vspace{-3cm}

\begin{figure}[H] \hspace{11cm}
\includegraphics[width=3.2 cm]{HU_Logo}
\end{figure}
% \vspace{5cm}
\begin{center}
  % \vspace{0.5 cm}
  \huge{\bf Measurements and Optimizations with Just-In-Time Code Generation on the Openflow Reference Implementation} \\ % Hier fuegen Sie den Titel Ihrer Arbeit ein.
  \vspace{1cm}
  \LARGE  Bachelorarbeit \\ % Geben Sie anstelle der Punkte an, ob es sich um eine
                % Diplomarbeit, eine Masterarbeit oder eine Bachelorarbeit handelt.
  \vspace{1cm}
  \Large zur Erlangung des akademischen Grades \\
  Bachelor of Science (B. Sc.)\\ % Bitte tragen Sie hier anstelle der Punkte ein:
         % Diplominformatiker(in),
         % Bachelor of Arts (B. A.),
         % Bachelor of Science (B. Sc.),
         % Master of Education (M. Ed.) oder
         % Master of Science (M. Sc.).
  \vspace{1.5cm}
  {\large
    \bf{
      \scshape
      Humboldt-Universit\"at zu Berlin \\
      Mathematisch-Naturwissenschaftliche Fakult\"at II \\
      Institut f\"ur Informatik\\
    }
  } 
  % \normalfont
\enlargethispage{10\baselineskip}
\end{center}
\vspace {1 cm}% gegebenenfalls kleiner, falls der Titel der Arbeit sehr lang sein sollte (original: 4cm)
%{3.2 cm} bei Verwendung von scrreprt, gegebenenfalls kleiner, falls der Titel der Arbeit sehr lang sein sollte
{\large
  \begin{tabular}{llll}
    eingereicht von:    &Samuel Brack  && \\ % Bitte Vor- und Nachnamen anstelle der Punkte eintragen.
    geboren am:         &27. März 1992  && \\
    in:                 &Memmingen  && \\
    &&&\\
    Gutachter: &Prof. Dr. Björn Scheuermann  && \\
              &Prof. Dr. Jens-Peter Redlich  && \\% Bitte Namen der Gutachter(innen) anstelle der Punkte eintragen
                 % bei zwei männlichen Gutachtern kann das (innen) weggestrichen werden
    &&&\\
    eingereicht am:     &   \hspace{3cm} verteidigt am: &  \\ % Bitte lassen Sie
                                    % diese beiden Felder leer.
                                    % Loeschen Sie ggf. das letzte Feld, wenn
                                    % Sie Ihre Arbeit laut Pruefungsordnung nicht
                                    % verteidigen muessen.
  \end{tabular}
}

\newpage


\chapter{Statement of authorship}

\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Selbststaendigkeitserklaerung
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\parindent 0cm
%%%%%%%%%%%%%%%%%%%%%%%%%%english version%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
I declare that I completed this thesis on my own and that information which has been
directly or indirectly taken from other sources has been noted as such. Neither this
nor a similar work has been presented to an examination committee.

  \vspace{3\baselineskip}
 
  Berlin, \today \hspace{0.25\linewidth}\parbox{0.3\linewidth}{\dotfill}
}
\newpage

%\begin{abstract}

%\end{abstract}

\addcontentsline{toc}{section}{Contents}
\setcounter{page}{1}
\tableofcontents{}

\pagebreak

\pagestyle{scrheadings}

\section{Introduction}
The growth of the Internet constantly poses new challenges to the producers of network equipment.
Today's applications like Multimedia, Peer-to-Peer data exchange, Web and Voice over IP are dependent on a transport network with
high data rates, low latency, soft real time properties and quality of service mechanisms.
This catalogue of network parameters is already implemented in the Internet protocol stack\cite{rfc3260, rfc3261, rfc5694, rfc3550}.
Another growing segment of Internet traffic is triggered by the outsourcing of 
enterprise IT infrastructure to Cloud computing companies like Amazon or Heroku.
The growth of the actual traffic itself leads to a steady demand for faster hardware handling the traffic on the networks.

The critical points in the internet's architecture concerning performance are the stations which have to decide for each packet what to do.
These are mostly firewalls, Level-2-Switches and Level-3-Routers implemented in special, single-purpose hardware.
In general, these machines inspect the header data of every incoming IP packet and process it 
following a rule set that has been specified before.
A recent trend in the networking community are Software Defined Networks (SDNs).
SDNs simplify the central and dynamic configuration of network hardware\cite{onf_whitepaper}.
Administrators can define network parameters and rules and the configuration on the end hosts is then managed by the SDN controller
This topic is discussed in detail in section \ref{sec:SDN}.

In this work the focus lies on the reference implementation of the SDN protocol suite OpenFlow.
OpenFlow is the first mechanism that specified the communication between the controller and the network hardware.
The reference implementation provides a software switch.
Optimization of that switch's matching engine is the main focus of this thesis.

\section{Basic Concepts}
\subsection{Internet Packets}
The Internet is a global network of packet switched networks\cite[Chapter 1.1]{kurose_ross} for exchanging data. 
The stream of data that is transported from its source to its destination is broken down into small chunks of bytes.
In packet switched networks, packets are the smallest independent unit of data transported.
A packet usually consists of header and payload data.
The packet header transports meta information for directing the packet to the correct host.
Depending on the protocol, headers may also contain meta data for congestion control or data order.
For instance, the TCP protocol transports additional information like sequence numbers in the packet headers\cite[Chapter 3.5]{kurose_ross}.
Payload data is a chunk of bytes from the original data stream.

When sending data over the Internet every packet is routed separately.
This can lead to differently chosen paths for one transmission, if it consists of more than one packet.
A router or switch has to inspect every incoming packet separately and then decide what action to apply.

\subsection{The Packet Classification Problem}
Due to the characteristics of packet switched networks, every station in the path of a data transmission on the Internet 
has to decide for each packet which action to execute.
Typical actions are DROP, REJECT, OUTPUT(\textit{port}), MODIFY and ACCEPT, as explained in table \ref{table:actions}.

\begin{table}
  \centering
  \begin{tabularx}{\textwidth}{l|X}
  Name&Description\\
  \hline
  DROP&Drop the packet and do not notify anyone.\\
  REJECT&Drop the packet and notify the previous station or the sender.\\
  OUTPUT(\textit{port})&Transfer the packet to the specified output port and send it to the next station.\\
  MODIFY&Modify some of the header data fields (usually in combination with OUTPUT).\\
  ACCEPT&Accept the packet locally and process it in the own network stack. The packet is not relayed to another host.\\
  \end{tabularx}
  \caption{Typical actions for network stations.}
  \label{table:actions}
\end{table}

\subsection{The IP Address Space}
The number of hosts on the Internet is growing permanently.
This contributes to a denser populated address space in case of IPv4.
Historically, the IPv4 address space was divided into three classes\cite{rfc1466}.
In 1993 the concept of Classless Inter Domain Routing (CIDR) was introduced.
Firstly, an overview over the classful Internet and its consequences on routing and the corresponding rule sets.

Very large networks were called Class A networks.
These networks were located in the address range of 0.0.0.0 to 127.255.255.255 and each network could include up to about 16 million hosts.
This means that only the first of the four bytes structuring an IPv4 address is fixed, the rest is freely selectable for each host by the owner of the address block.
Due to their size, the entire IPv4 address space can only contain 128 of these networks.
Class A networks were assigned to big companies and organizations in the early days of the Internet.

A more common class especially for smaller organizations like German universities were Class B networks.
These networks had two of the four bytes in an IPv4 address fixed.
This lead to 16384 possible Class B networks with up to about 65000 hosts each.
Similarly, Class C networks were allotted to small entities.
Each Class C network contains up to 254 hosts and has the first three of the four address bytes set.

This layout facilitated the routing problem.
Rule sets could be relatively organized and small.
For example, an entire Class An network only needed one routing rule to have its traffic routed there.
Additionally, the first byte of a network address already determined the affiliation in its net class.
On the other hand, this system had major disadvantages.
Firstly, there are only three sizes for networks.
This automatically leads to networks too big for the purpose and an enormous waste of addresses.
Another problem is the lack of flexibility.
Consider a network that has to be shrinked or enlarged.
That operation could only properly be executed by moving into another network class instead of extending the 
previously used address space into its \enquote{neighbouring} area.

In 1993, the IETF introduced Classless Inter Domain Routing\cite{rfc1518} \cite{rfc4632}.
The main idea is to give up the three static classes and to introduce dynamic subnet sizes.
In principle, an address can be part of a network of any size and is not bound to be in a certain class.
This flexibility leads to the necessity of defining the size of the sub net for every sub net.
In the old scheme, the address 1.2.3.4 was definitely in the Class A network 1.0.0.0 -- 1.255.255.255.
With CIDR, the containing address space must be determined by defining a fixed prefix for each of the addresses in the sub net.
Usually, this is done by adding a slash followed the number of fixed bits after the sub net's first address.
For example, the previous Class A network becomes 1.0.0.0/8, because the first 8 bit are fixed and the rest is part of the sub net.
With this notation, the entire Internet becomes 0.0.0.0/0 and one single host is for example 141.20.33.1/32.

\subsection{Longest Prefix Matching}
CIDR opens the opportunity to route different parts of a sub net to different places.
For example, a rule set can contain a rule for the address space 141.20.0.0/16 and another rule for the included sub net 141.20.33.0/24.
These prefixes overlap and if for example a packet with the address 141.20.33.123 arrives, both rules match this packet.
Longest prefix matching signifies the idea that shorter prefixes are less favorable when matching packets, so that rule 141.20.33.0/24 matches.
Packet matchers need to have capabilities to match a packet to its longest matching prefix.
Usually, this property of CIDR leads to an increasing size of rule sets in the respective Internet traffic handlers. %TODO: Grafik zum Beispiel, mehr Text
Sub nets can be divided into numerous smaller sub nets and each network split has to be mapped in routing tables and rule sets.
Therefore, an algorithm used for matching Internet packets has to be capable of longest prefix matching.

\subsection{Affected Internet Infrastructure}
One main point in optimization thus lies in the matching algorithms executing this process.
Many traditional rule sets require five header fields for matching: Source IP address, destination IP address, transport protocol, source port and destination port.
The last two fields imply the usage of TCP or UDP as transport protocol, as other protocols may be ignorant of the concept of ports (e.g. ICMP).
Modern packet filters often need to match or even modify more than these five header fields.
These include for example VLAN tags, QoS information or MAC source and destination addresses.

Matching algorithms become slower the more header fields they have to match because more data is relevant per packet.
Additionally, some fields require rules that imply certain ranges or prefixes, for example IP or hardware addresses.
These constraints make it less attractive to implement simple matching algorithms and in order to match with high speed, more sophisticated
algorithms have to be used for use in these fields.

Another undesired result of the growth of the Internet is the increasing size of routing tables and the problems that are introduced by this.
Recently, more than approximately 500.000 routes were announced via the Border Gateway Protocol, the Internet's top-tier routing protocol.
This lead to outages of network connectivity at some providers due to a default limit in older Cisco routers being too small\cite{outage}.
Rebooting solves this problem for a while, but in future there certainly are limits that might not be as easily circumventable as this one.

%TODO: Openflow/SDN
\subsection{Software Defined networks}
\label{sec:SDN}
Software Defined Networking (SDN) describes the general idea to decouple 
the configuration of network parameters from the actual hardware and to 
introduce a new layer of abstraction in corporate networking\cite{onf_whitepaper}.
These networks can be separated into two logical units: the control and the data plane.
The control plane is used for configuring and updating the network hardware, e.g. inserting new rules into a firewall.
More sophisticated tasks like network monitoring, intrusion detection or automatic reconfiguration in certain events also require a control infrastructure.
The data plane handles the incoming network traffic and acts accordingly to the objectives defined in the control plane.

\subsubsection{OpenFlow}
One popular instance of an SDN is OpenFlow\cite{openflow_spec10}.
This project is intended to establish a virtual network system on real hardware for educational and research use cases.
A key feature of OpenFlow is the control channel system.
One controller has connections to all existing hard- and software switches and can define their behaviour from a central position.
The controlled SDN switch then acts accordingly and handles the traffic as required.

Another key feature of OpenFlow marks the ability to change the underlying hardware transparently.
The abstraction layer hides the details of the different systems so that 
the configuration on controller level can remain the same regardless of the hardware used.
Additionally, network design changes can be implemented faster due to the central configuration plane.
Even automatic processes can alter the network layout dynamically, for instance when load balancing 
or in distributed database setups.

The main objective of this work is to implement a faster matching engine in the software switch of the OpenFlow 1.0 reference implementation.
Currently, that matching engine uses a linear search in the specified rule set when classifying packets.
This approach may be fast enough in cases of small rule sets but with a growing number of rules in its database, the efficiency of a linear search decreases.

\section{Related Work}
Speeding up packet classification is one of the current research topics in the computer network community.
Therefore, several algorithms have been developed in the last years.
The bitvector algorithm is not the only promising idea to speed up packet matching in modern network hardware.
An overview over these algorithms can be gained from \cite{algorithms_survey}.
The authors compare a detailed list of algorithms and discuss their advantages and downsides.
Approaches to the packet classification problem include the usage of tries, 
hash maps or geometric algorithms\cite{hicuts} in order to perform significantly 
faster than searching the matching rule in a linear list.

Real-world applications of these theoretical concepts are numerous and have been evaluated in different projects.
Following, there is an overview over different projects using a software packet filter environment.

The Iptables\cite{iptables} packet filter was improved in the HiPAC project \cite{hipac}, which was founded in a diploma thesis \cite{heinzhigh}.
Another project focuses on the implementation of EffiCuts in an OpenFlow environment \cite{stimpfling2013optimal}.
They also faced the challenge to improve the efficiency of packet classification on more than the usual five-tuple of header fields.
OpenFlow 1.0.0 \cite{openflow_spec10} requires at least 12 header fields to be matched, later versions are operating on even larger sets.
To address this problem, they extended the original EffiCuts algorithm in order to achieve a lower memory usage profile.

Other research groups focus on implementing wire speed packet matching in (programmable) hardware instead of software.
The bitvector approach \cite{bv} has been evaluated in FPGAs \cite{bitvector_fpga} \cite{qu2013fast}.
However, these papers mainly focus on five-tuple rule sets, which decreases the complexity of the problem compared to an OpenFlow 12-tuple.

Further improvement on the bitvector algorithm includes the elimination of the linear processing of the resulting bitvectors itself:
When all dimensions are matched and the resulting bitvectors are retrieved, these vectors have to be ANDed bit per bit until a one bit is found.
This obviously results in an $\mathcal O(n)$ worst case runtime.
The ABV algorithm \cite{abv} implements a hierarchical system of bitvectors with fixed length and runs in $\mathcal O(log\ n)$.
However, more memory space is needed to store the bitvectors of the respective hierarchies.

Another approach to improve matching performance in a packet filter is to reorganize the rule set.
One way to perform such a reorganization is the compression of the rule set as introduced in \cite{firewall_compressor} and \cite{redundancy_removal}.
They reduce the number of the rules significantly whilst persisting its semantics.
These optimizations can be done offline and before the rule set is loaded into the firewall.
Additionally, the firewall can perform a heuristic analysis of the traffic patterns and re-order the rule set accordingly while operating.

The advantage of that strategy is that the matching engine itself has not to be changed and can be left untouched.
This can be useful in black box scenarios, where the matching engine's source code is not open to the end user.
However, that idea requires to reorganize the desired rule set and makes updating more complex.
In case of high-frequent updates this strategy will hit its limitations, 
as the optimization steps often require the consideration of the entire rule set and not only the updated part.

A just in time (JIT) compiled ruleset has been implemented in \cite{bpfplus}.
The general idea is to compile the rule set to an executable written in a virtual machine intermediate language.
That bytecode is automatically generated from a high-level rule matching language.
The matching process is done linearly and by jumping to different execution points in the executable (but only in forward direction).
For instance a packet might be checked if it is an IP packet, then relayed to the next section where the source and destination addresses are checked.
From there, a jump might go out to a section where transport protocols are checked and so on.
Generally, that process is considerably faster than a classic search for matches in a list.
However, it is impossible to parallelize that lookup process, because each matching step relies on the outcomes of the ones before.
In the algorithm used in this work, the different matching dimensions are 
completely independent and much more distributable.

\section{The Bitvector Algorithm}
\subsection{General Description}
The bitvector algorithm \cite{bv} is an efficient solution to the packet classification problem, as described in the introduction section.
This algorithm is designed for matching multi-dimensional header data in a short time.
The basic idea of this algorithm is to think of the ruleset as a set of multi-dimensional hypercubes.
Each header field represents one dimension in this geometric object, so that every hypercube (which represents exactly one rule) has as many dimensions as the packet matching engine is operating on.
The extent of one rule in one dimension is therefore an interval between two integers.
These delimiting integers are determined by projecting the hypercube onto the relevant dimension.
If cubes (and their respective rules) are overlapping, one point on the dimension can be the target of multiple cubes' projections. 
This property leads to a model, where for any given point in a matching dimension, there is a set of cubes (and therefore rules) that are projected on intervals containing this point.
If there are no matching rules for a point there is no cube projecting an interval to the relevant dimension.

The bitvector algorithm collects these projected rules for every dimension.
After that, the edges of the rules' intervals are determined.
Every edge then stores a vector of bits with $n$ bits length.
For each original rule $r$ in the rule set with $n$ rules this bit vector stores a $1$ if and only if $r$ is projected on the interval beginning at the current edge.
If $r$ is not projected on the current interval, a $0$ bit is stored.
This construction is done in every dimension for every edge.

For better understanding of his algorithm, consider packet headers consisting only of a source and a destination address.
These addresses are four bit wide each.
For example, the rule set defined in table \ref{table:bv_ruleset} is a valid rule set in this scenario.
Figure \ref{fig:bv-normal} holds a graphical representation of this rule set.
Each rectangle (a two-dimensional hypercube) represents one of the defined rules.
Corresponding bit vectors are displayed at every intersection of a rule border and the axis of the coordinate system.
These vectors store the information which rules are matching right or above the delimiter where the bit vector's scope begins.
The first bit in a vector determines whether Rule 1 is matching, the second determines that for Rule 2 et cetera.

When two or more rules are overlapping (in this example rules 1 and 2 happen 
to overlap in a section) the bit vectors display the validity of both rules in the affected area.
Therefore, Longest Prefix Matching is easily supportable in this approach, 
as the shorter prefixes can be inserted firstly and thus have a higher matching priority than longer ones.

\begin{table}
  \centering
  \begin{tabularx}{\textwidth}{l|X|X}
  Rule&Source Addresses&Destination Addresses\\
  \hline
  1&3 -- 11&4 -- 13\\
  2&1 -- 5&2 -- 5\\
  3&8 -- 13&0 -- 3\\
  \end{tabularx}
  \caption{Example rule set for the bitvector algorithm.}
  \label{table:bv_ruleset}
\end{table}

\begin{figure}
\centering
\includegraphics[height=0.8\textwidth]{images/bitvector-L1-2}
\caption{The rules and the resulting bit vectors.}
\label{fig:bv-normal}
\end{figure}

\subsection{Lookup}
When looking up a packet with the bitvector algorithm, one has to determine a point to look up in every matching dimension.
These points are header data, for example one point is the source IP address, another one is the destination IP address or the VLAN ID.
When all relevant points are determined the lookup process works as follows:
Firstly, there is a search for the target point in every dimension.
In this implementation, binary search returns the nearest left edge (constructed when inserting the rules) of the search space.
This edge contains the bitvector with $n$ bits length, where $n$ is the size of the rule set.

Again, the example from figure \ref{fig:bv-normal} will be considered.
Furthermore, assume that packets P1 with header data $(4, 4)$ and P2 with header data $(14, 7)$ arrive at the switch.
For P1, the source address bit vector can be looked up by finding the bit vector left of the point $4$ on the source address axis.
The same process applies for the destination address.
In case of P1, the algorithm thus returns the bitvector $(1, 1, 0)$ in the source address dimension and the bitvector $(1, 1, 0)$ in the destination address dimension.
Figure \ref{fig:bv-lookup} holds a graphical representation of this process.

\begin{figure}
\centering
\includegraphics[height=0.8\textwidth]{images/bitvector-L1_3}
\caption{Looking up packets P1 and P2.}
\label{fig:bv-lookup}
\end{figure}

The same lookup process can be done for P2, which returns the $(0, 0, 0)$ and $(1, 0, 0)$ bit vectors.
As one can easily see, in case of P2 there exists no matching rule for both dimensions.
This will also be determined by the next step of the algorithm.

After that, all bitvectors from all dimensions are joined by a bitwise AND.
The resulting vector then indicates by a $1$ at position $p$ that the packet has matched rule $p$.
Generally, there can be one or more matching rules, for example when default rules exist, that match every packet.
In the example from above, this case occurs with packet P1, where rules R1 and R2 are matching.
In order to determine the highest priority matching rule, the resulting bitvector is then scanned for the leftmost set 1-bit, which is the first bit standing for R1 in the example.
The index of this bit in the bitvector then determines the best matching rule in the rule set.

After that, the actions defined in the rule can be executed by the network device and the next packet in the queue can be matched.
In case of no matching rule (for example when matching P2), the resulting bit vector for all dimensions is entirely filled with zeroes.
How this is handled is implementation dependant, however in most cases some default action will be executed.
Often the packet is just dropped when resulting in no match.

\subsection{JIT lookup}
To further speed up the lookup process, another optimization has been implemented.
At each lookup, the algorithm has to perform a binary search on the bitvectors' locations in each dimension in order to find the matching bitvector for the current packet.
These locations can be interpreted as delimiters between the realms of the bitvectors.
In the above example, if the lookup process receives a packet with a source IP address value of 3, the algorithm has to find the first bitvector in the source IP dimension. %TODO: example abgleichen!
For every header field in the 12-dimensional OpenFlow header the algorithm has to yield exactly one bitvector.
This lookup process over the entire delimiter space requires several memory accesses for every lookup.
The general idea to speed up this operation is to precompute a function that is specific for each dimension and returns the bitvector's index in one dimension when given the header value to be matched.

The function is designed to have zero memory accesses when looking up header values.
Therefore it performs the binary search only on precomputed values, which 
leads to the necessity of rebuilding the function at every rule set update.
Clearly, that leads to a performance disadvantage for fast changing rule sets at the benefit of having generally faster lookups.

Implementing that functionality has lead to a just in time generated function written in machine 
language\footnote{The x86\_64 architecture with Intel assembly language has been used.}.
Every assembly instruction was split up into its respective opcodes following the 
Intel 64 and IA-32 Architectures Software Developer Manuals. %TODO: cite???
For example, the opcodes for the instruction 
\textsf{mov \%rsp,\%rbp} (Copying the value of the stack pointer to the base pointer) 
are $\texttt{0x48}, \texttt{0x89}, \texttt{0xE5}$.
After that, these generated opcodes were copied into an executable memory block and a function pointer to that block has been returned.

The algorithm for constructing the JIT used in this implementation produces a slightly modified binary search.
Note that in the generated function, the matchable packet header data point is stored in the register \textsf{\%rax}.
The first call of the recursive algorithm \ref{alg:jit} is invoked with the entire array of delimiter values, a freshly generated area of executable memory, 
zero as the lower bound of operation and the last index in the delimiters array as last argument.
Its return value is the length of newly written bytes to the executable memory in order to perform relative jumps over entire code blocks.

Every time \textsf{Insert} is called in algorithm \ref{alg:jit} the opcodes 
of the corresponding assembler instruction are looked up and appended to the executable memory.
Due to working in an Intel microprocessor, numeral arguments have to be 
transformed into little-endian byte order in the \textsf{Insert} function.

\begin{algorithm}
\begin{algorithmic}
\Function{JIT\_creation}{delimiters[], *executable\_memory, low\_index, high\_index}
    
    \If{$(hi\_index - low\_index) == -1$} 
    
        \State $executable\_memory \gets 0$
        
        \Return 0
        
    \EndIf
    
    \If{($hi\_index == low\_index$}
    
        Insert cmpq delimiter[low\_index]
        
        Insert jb 0x7 //offset = len(mov) + len(pop\_ret)
        
        Insert mov low\_index
        
        Insert pop\_ret
        
        \If{$low\_index == 0$}
        
            Insert mov 0
            
            Insert pop\_ret
            
        \Else
            
            Insert mov low\_index
            
            Insert pop\_ret
            
        \EndIf
        
        \Return memory\_len
    \EndIf
\EndFunction
\end{algorithmic}
\caption{The algorithm used to create the JIT-compiled function.}
\label{alg:jit}
\end{algorithm}

\section{Evaluation}
\subsection{Unit Tests}
An important goal in every software project is to ensure that the program operates correctly.
The first step in this quality assurance process is to design unit tests for the modules in the software.
In this project the matching engines have been tested separately before integrating them into the OpenFlow switch.
Additionally, the just in time generated code has been tested to work properly.

\subsection{Acceptance Test}
In order to guarantee the correctness of the two new implementations a predefined acceptance test was developed.
A reasonable assumption is that, if given a rule set and a corresponding trace, the old and new implementations are behaving the same.
This was tested by deriving traces from randomly generated rule sets with the Classbench\cite{classbench_website} tool \textsf{trace\_generator}.
For each implementation, there was a virtual network set up with ten hosts and a switch connecting them in a star topology.
The generated traces were then converted into packets and fed into the switch with 50\ ms delay between each packet from a particular host.
After finishing this process, each host was queried on how many packets arrived there.
All implementations generated the same packet statistics on the hosts, therefore it is assumed they are behaving correctly.

\subsection{Performance Evaluation}
The evaluation of the performance of the newly implemented matching algorithm has been executed in a virtual environment.
\textsf{mininet}\cite{mininet} provides an easily usable and lightweight virtual network on a local computer.
It creates two new local interfaces and connects them through a local OpenFlow switch.
This switch can be configured with \textsf{dpctl}, a tool included in the tool chain of the OpenFlow reference implementation.
Rule set updates thus are done via a command line call of that tool.
The evaluation system is a computer with a quad core Intel Xeon E3-1270 v3 CPU 
running at 3.5 GHz and 16 GB of memory with an Ubuntu Linux 14.04 LTS operating system.
This computer was idle when performing the tests.

\subsubsection{Matching Performance}
The matching performance evaluation was setup in the following way.
\begin{itemize}
    \item Creation of different sized rule sets from 100 to 3500 rules.
        For measuring average performances there are ten different rule sets created for every rule set size.
    \item Generating good, average and bad case sub-rule sets. 
        Each original rule set is split into thirds and each of them is saved separately.
    \item Generating traces for every sub-rule set.
        Using the Classbench\cite{classbench_website} tool, a packet trace is generated for every previously generated rule set.
        That means that for every rule set three traces are produced: 
        one for the good case sub-rule set, one for the average one and one for the bad case set.
\end{itemize}
A packet trace consists of packet header data like IP source and destination addresses, transport and Internet protocols et cetera.
Every trace entry can be translated into a packet that is sent into the OpenFlow switch's matching engine.
The performance was tested by looping through every generated trace for ten seconds and sending packets through the switch.
After that time the number of received packets was measured on the destination host with the \textsf{netstat} command.

The results in figures \ref{fig:eval_good_case}, \ref{fig:eval_average_case} and \ref{fig:eval_bad_case} show that the List implementation
clearly suffers from hard performance losses when inserting more rules.
Both bitvector implementations outperform the linear search algorithm after inserting about 300 rules.
The initial negative peak just as the dent at 500 inserted rules can be caused by an unfortunate rule set and trace combination.
However, it is not likely that these performance holes are caused by other active processes on the computer during the evaluation.
All evaluation tasks were distributed over the time, so that the ten runs 
for one value guarantee some independence of external factors over the time.

\begin{figure}
\centering
\includegraphics[height=0.4\textheight]{images/eval_b}
\caption{Matching performance: Good case.}
\label{fig:eval_good_case}
\end{figure}

\begin{figure}
\centering
\includegraphics[height=0.4\textheight]{images/eval_a}
\caption{Matching performance: Average case.}
\label{fig:eval_average_case}
\end{figure}

\begin{figure}
\centering
\includegraphics[height=0.4\textheight]{images/eval_w}
\caption{Matching performance: Bad case.}
\label{fig:eval_bad_case}
\end{figure}

\subsubsection{Insertion Time}
Figure TODO shows the significant loss in efficiency when inserting rules. %TODO: Grafik
The two graphs show the duration of an update with different sized rule sets in the JIT implementation and in the conventional approach.
Because of the requirement that the matching engine has to be operable 
immediately after every update operation, every update implies a complete regeneration of the JIT code.
That behaviour explains the additional update time seen in the measured data. 

\subsubsection{Implementation Complexity}
The three algorithms are implemented in C.
To give a rough estimate of complexity table \ref{table:loc} shows the approximate size of the implementation sizes measured in lines of code.

\begin{table}
  \centering
  \begin{tabularx}{\textwidth}{l|XXX}
  &List&Simple Bitvector&JIT Bitvector\\
  \hline
  Insertion&&&\\
  Lookup&&&\\
  \end{tabularx}
  \caption{Lines of code for all three implementations.}
  \label{table:loc}
\end{table}

\subsubsection{Memory Usage}

\section{Future Work}
Future work in this particular area can steer in manifold directions.
One of the main objectives is further optimization of the matching algorithm.
One possibility to speed up the switch is to lower the time used for the JIT code generation.
Modifying the existing JIT function instead of deleting the old one and building 
a new one from scratch might be a worthwhile task.
This should save some time when updating the rule set.
Especially in environments with fast-changing rule sets this idea may offer 
a significant advantage over the current implementation.

Another idea that comes to mind is to implement a heuristic that detects 
the most popular flows of the last time span in an operating switch.
After gathering traffic data for a while it might prove beneficial to tune 
the JIT function in such a way that the search for packet header data in a popular flow returns faster.
Depending on the type of traffic, this optimization may either cause a massive performance boost or no real advantage.
The latter case enters if there are no real flows recognizable in the traffic because it is very sparse.
But in most real world cases there exist observable traffic patterns.

\newpage
\addcontentsline{toc}{section}{References}
\bibliographystyle{acm}
\bibliography{references,paper-build/conferences-crossref,rfc}

\end{document}
